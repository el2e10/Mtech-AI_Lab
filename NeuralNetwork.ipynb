{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    \n",
    "    def __init__(self,x,y):\n",
    "        self.input = x\n",
    "        self.y = y\n",
    "        self.w1 = np.random.rand(self.input.shape[1],4)\n",
    "        self.w2 = np.random.rand(4,1)\n",
    "        self.output = np.zeros(y.shape)\n",
    "        self.cost = np.inf\n",
    "        \n",
    "    def sigmoid(self,x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def sigmoid_derivative(self,x):\n",
    "        return x * (1 - x)\n",
    "    \n",
    "    def smse(self):\n",
    "        test = np.sum(np.square(np.abs(self.output - self.y)))\n",
    "        self.cost = test\n",
    "          \n",
    "    def feedforward(self):\n",
    "        summation_one = np.dot(self.input,self.w1)\n",
    "        self.layer1 = self.sigmoid(summation_one)\n",
    "        summation_two = np.dot(self.layer1,self.w2)\n",
    "        self.output = self.sigmoid(summation_two)\n",
    "        \n",
    "    def backpropagation(self):\n",
    "        temp_w2 = np.dot(self.layer1.T, (2 * (self.y - self.output) * self.sigmoid_derivative(self.output)))\n",
    "        temp_w1 = np.dot(self.input.T,np.dot(2 * (self.y - self.output) * self.sigmoid_derivative(self.output),self.w2.T) * self.sigmoid_derivative(self.layer1))\n",
    "    \n",
    "        self.w1 += temp_w1\n",
    "        self.w2 += temp_w2\n",
    "        \n",
    "    def main(self):\n",
    "        self.feedforward()\n",
    "        self.backpropagation()\n",
    "        self.smse()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cost at 0th iteration is inf\n",
      "The cost at 500th iteration is 0.014108803379032468\n",
      "The cost at 1000th iteration is 0.0042135181661688255\n",
      "The actual outputs are:\n",
      " [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "The predited outputs are:\n",
      " [[0.01197902]\n",
      " [0.97605099]\n",
      " [0.97292944]\n",
      " [0.02914942]]\n"
     ]
    }
   ],
   "source": [
    "# training data\n",
    "X=np.array(([0,0,1],[0,1,1],[1,0,1],[1,1,1]), dtype=float)\n",
    "y=np.array(([0],[1],[1],[0]), dtype=float)\n",
    "\n",
    "\n",
    "\n",
    "NN = NeuralNetwork(X,y)\n",
    "for i in range(1500):\n",
    "    if(i % 500 == 0):\n",
    "        print(f\"The cost at {i}th iteration is {NN.cost}\")\n",
    "        \n",
    "    NN.main()\n",
    "    \n",
    "print(f\"The actual outputs are:\\n {y}\")\n",
    "print(f\"The predited outputs are:\\n {NN.output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
